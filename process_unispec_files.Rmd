---
title: "Process LTER Unispec Data"
author: "Ruby An"
date: "December 17, 2018"
output:
  html_notebook:
    number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

## Required Packages
library("tidyverse")
library("knitr")
source("unispec_functions.R") # file loads required functions

## Useful vectors for standardizing names and filtering data
WSG <- c("WSG1", "WSG23")
SHB <- c("SHB1", "SHB2")
site_list <- list("MAT", "LMAT", "MNAT", "NANT", "DHT", WSG, SHB, "HST")

CT <- c("CT","CT1","CT2")
NP_gradient <- c("F0.5","F1","F2","F5","F10") # for LOF site
N_types <- c("NO3", "NH4") # for LOF site
trtmt_list <- list(CT, "N", "P", "NP", NP_gradient, N_types)

## Useful vectors for plotting
# Color sequences
pur_pal <- RColorBrewer::brewer.pal(5, "Purples")
```

# How to use this R Markdown Notebook: 

This R Markdown document will walk you through the steps to process Unispec-DC data collected from the Toolik Arctic LTER plots. For background and additional info, consult *A Peopleâ€™s Guide to Unispec-DC Measurements and Data Prep* in the LTER files. 

Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>. For more details on R as a programming language for data analysis, see <https://r4ds.had.co.nz/index.html>.

**To use this notebook INTERACTIVELY**: set `output: html_notebook` in the header at the top of this document. In this mode, it is useful select the **"Preview in Viewer Pane"** option (under the "gear" icon). The preview will then update every time you rerun code chunks and save this file. 

**To generate a STATIC report**: choose **Knit to HTML** or PDF to generate a document that includes both written content as well as the output of any embedded R code chunks within the document.


# Choose Directory

Select the folder containing the unispec files you want to process. Run the following code chunk interactively in RStudio to set folder via pop-up window. 
```{r directory}
## INTERACTIVE CODE (use when in RStudio)
# library("rChoiceDialogs") # for interactively selecting file directories
# data_path <- rchoose.dir(caption = "Select Unispec files directory")

## STATIC CODE (use when Knitting)
data_path  <- "UnispecData/Unispec1/" 
```

**Chosen Directory**: `r data_path`

This directory should contain both the `.spu` files you wish to process and a corresponding `*_unispec_key.csv` file. The key file matches the .spu files to the date, site, block, treatment, plot, & measurement and specifies which white references to use to correct for instrument error. 

# Load Unispec Data 
Run the following code chunks to load & join keys to data from your chosen directory. 

## Load Keys 
```{r key} 
## Find all file keys 
### alter search pattern to choose specific key(s)
key_files <- list.files(path = data_path, pattern = "*_key.csv", full.names = T, recursive = T)

## Read in data from filekeys 
key_list <- data_frame(keyname = key_files) %>% # create dataframe
  mutate(key_contents = map(keyname, function(x) read_key_file(x))) 
# read_key_file() is a function I wrote located in the file "unispec_functions.R"
# map function: super useful to apply function to objects without slow "for" loops

## Unpack into usable dataframe 
keys <- unnest(key_list)
```
**Chosen Keys**: `r key_files`

## Load Data
```{r spu_data, cache.lazy=T}
## Find .spu files
### alter data_path or specify Date(s) or Site(s) to read files
files <- list.files(path = data_path, pattern = ".spu$", full.names = T, recursive=T)

## Read data from files (can take minutes)
data_list <- data_frame(filename = files) %>% # create dataframe
  mutate(file_contents = map(filename, function(x) read_spu_file(x)))

## Unpack into usable dataframe 
data <- unnest(data_list) 
```

## Join Data & Keys
```{r join_keys_data}
## Join all data matching keys dataframe (drops any non-matching data),
##  by columns (Date, Site, FileNum)
df <- inner_join(data, keys) %>% 
  filter(Wavelength >= 400 & Wavelength <= 1000) # Choose relevent wavelengths 
```

The following table lists the dates and sites of the files contained in your chosen directory: 
```{r df_table, echo=F}
## Sites per Date table to display
df_table <- df %>% 
  select(Date, Site) %>% 
  distinct() %>% 
  group_by(Date) %>% 
  do(Sites = t(.[-1])) %>% 
  mutate(Sites = paste( unlist(Sites), collapse=','))

kable(df_table)
```



# QAQC
Quality check unispec data using the following code chunks.

## Check White References
White references correct for instrument & cable irregularities. Multiplying by the correction factor (ChA/ChB) smooths out the spectra. If multiple file numbers are listed (typically 5), the correction factors are averaged. 

### Plot All References
The following code chunk plots all the white reference spectra in your chosen directory.

```{r refs, echo = F, warning=F}
## Find all white reference files 
ref_data_all <- df %>% 
  filter(str_detect(Treatment, "REF"))%>% # extract reference data 
  separate(Block, into = c("BX1", "BX2", "BX3", "BX4"), sep = ",") %>% # expand string entry in "Block", necessary if different ref for different blocks at same site
  gather(Block, BlockString, BX1:BX4) %>% # re-condense into one column
  mutate(Block = str_squish(BlockString), BlockString=NULL) %>% # remove whitespace from Block names introduced by "separate" function
  filter(!is.na(Block)) %>% # remove empty rows for site w/out B3 or B4
  mutate(CorrectionFactor_REF = ChA/ChB)

## Plot ALL Correction Factors for quality check 
cor_factor_plot_all <- ggplot(data = ref_data_all, mapping = aes(x = Wavelength, y = CorrectionFactor_REF)) +
  geom_line(aes(color=Treatment, linetype=Measurement, alpha=Block)) +
  facet_grid(Site ~ Date) + 
  scale_alpha_discrete(range=c(1, 0.5)) # set transparency by block

cor_factor_plot_all

```


Look for correction factors very far from 1.0 or with odd peaks. 


### Plot Zoom Check References
Run the following code chunk interactively in RStudio to check references at specific sites/dates. 
```{r check_refs}
# Useful Vectors for filtering
sites <- unlist(site_list)
dates <- df %>% select(Date) %>% unique() %>% slice(1:n()) %>% c() # list of dates present in data

## SPECIFY SITE/DATE/ETC to ZOOM IN ON
check_sites <- c("SHB1")
check_dates <- dates[[1]] # necessary to unlist dates vector

ref_check <- ref_data_all %>% 
  filter(Date %in% check_dates) %>% 
  filter(Site %in% check_sites) 

## Plot Specified Correction Factors for quality check 
cor_factor_plot_zoom <- ggplot(data = ref_check, mapping = aes(x = Wavelength, y = CorrectionFactor_REF)) +
  geom_line(aes(color=Treatment, linetype=Measurement, alpha=Block)) +
  facet_grid(Site ~ Date) +
  scale_alpha_discrete(range=c(1, 0.25))

cor_factor_plot_zoom
```

Look at associated dataframe to check info, specifically: *Weather*, *Notes*, or *int* (Integration Time) columns.
```{r ref_check_files, echo=F}

## EXAMINE SPECIFIC info: check Integration, Notes, Weather, filename, etc. 
ref_check_files <- ref_check %>% 
  select(-c(Wavelength, ChA, ChB, CorrectionFactor_REF, keyname, Time)) %>% 
  unique()

### View dataframe of ref_check_files
kable(ref_check_files)
```

## Choose White References:
Based on the above quality check, choose reference files by entering the appropriate file numbers in **`r key_files`** for the rows where the column *Treatment* = **REF**. There are typically 5 reference measurements per *Date* / *Site*. 

Then rerun the **Load Keys** and **Join Data & keys** sections above to update the `df` dataframe. The following plots your chosen references.

```{r ref_table, echo=F}
options(knitr.kable.NA = '')

## Find REF files for correction factors
ref_data <- df %>% 
  filter(Treatment == "REF") %>% # extract reference data 
  separate(Block, into = c("BX1", "BX2", "BX3", "BX4"), sep = ",") %>% # expand string entry in "Block", necessary if different ref for different blocks at same site
  gather(Block, BlockString, BX1:BX4) %>% # re-condense into one column
  mutate(Block = str_squish(BlockString), BlockString=NULL) %>% # remove whitespace from Block names introduced by "separate" function
  filter(!is.na(Block)) %>%  # remove empty rows for site w/out B3 or B4
  mutate(CorrectionFactor_REF = ChA/ChB) # calculates correction factor


## Plot CHOSEN Correction Factors 
cor_factor_plot  <- ggplot(data = ref_data, mapping = aes(x = Wavelength, y = CorrectionFactor_REF)) +
  geom_line(aes(color=Measurement, linetype=Block, alpha=int)) +
  facet_grid(Site ~ Date)

cor_factor_plot


## Output Table of Chosen References
ref_choice <- df %>% 
  filter(Treatment == "REF") %>% 
  select(Date, Site, Block, Weather, Notes, Measurement, FileNum) %>% 
  distinct() %>% 
  mutate(Measurement = str_c("P", Measurement))%>% 
  spread(Measurement, FileNum) %>% 
  unite(FileNums, P1:P5, sep=",") 

kable(ref_choice, caption="White Reference Files")
  
```

## Apply References
Apply your chosen references to actual spectral data to create the tidy dataframe `df_tidy` containing corrected sepectral reflectance values. 

```{r apply_refs, echo=FALSE}
## Average 5 chosen ref measurements per DATE/SITE/BLOCK 
ref_summary <- ref_data %>% 
  group_by(Date,Site,Block,Wavelength) %>% # group_by(Date,Site,Block,Wavelength, int) %>% 
  summarize(ChA_REF = mean(ChA), ChB_REF = mean(ChB), CorrectionFactor_REF = mean(ChA/ChB), int_REF = mean(int), Notes_REF = list(Notes))

## Join DATA with REFS 
df_ref <- inner_join(df, ref_summary) %>% 
  select(Date, Time, Site, Block, Treatment, Measurement, Wavelength,  int, int_REF, ChB, ChA, ChB_REF, ChA_REF, CorrectionFactor_REF, Weather, Notes, Notes_REF, filename, FileNum, keyname) %>%
  mutate(raw = ChB/ChA) %>% # the raw reflectance
  mutate(correct = raw*CorrectionFactor_REF) %>% # this step calculates the corrected reflectance
  gather(Type, Reflectance, raw:correct) 

df_tidy <- df_ref %>% 
  mutate(Site = replace(Site, Site %in% WSG, "WSG")) %>% # rename WSG1 & WSG23 to WSG
  mutate(Site = replace(Site, Site %in% SHB, "SHB")) %>%  # rename  SHB1 & SHB2 to SHB
  filter(Type == "correct") %>% # drop raw reflectance
  select(-Type) 
```

## Save Spectral Data

```{r save_spectra, echo=T}

# SAVE CORRECTED SPECTRA if you want the dataframe or .csv for later
# unispec_data_2018 <- df_tidy %>% 
#   filter(Type=="correct") %>% 
#   select(-Type)
# save(unispec_data_2018, file = "unispec_data_2018.Rda")

```

# Investigate Spectral Data

## Plot Spectra: Site vs. Block
For the following code, make sure you select only one date per site. The 5 measurements per plot are averaged as a line and one standard deviation above and below shaded. Interactively edit the "PLOT SELECTION" vectors in the code chunk below to investigate specific data.

```{r plot_spectra_blocks, echo=F}
# PLOT SELECTION 
dates <- lubridate::ymd("2018-06-22", "2018-06-25")
sites <- c("HST", "MAT", "LMAT",  "MNAT", "NANT", "WSG", "DHT", "SHB")
blocks <- c("B1", "B2", "B3", "B4")
trtmts <- c("N", "NP", CT, NP_gradient) 
measures <- c("1", "2", "3", "4", "5")

# Data Comparison Format
df_block <- df_tidy %>% 
  filter(Site %in% sites) %>% 
  filter(Block %in% blocks) %>% 
  filter(Treatment %in% trtmts) %>% 
  filter(Date %in% dates) %>% 
  group_by(Site, Block, Treatment, Date, Wavelength) %>% 
  summarize(
    avg_reflect = mean(Reflectance),
    max_ref = max(Reflectance),
    min_ref = min(Reflectance),
    sd_reflect = sd(Reflectance)
    ) 

ggplot(data = df_block, mapping = aes(x = Wavelength, y = avg_reflect)) +
  geom_line(aes(color=Treatment)) + 
  geom_ribbon(aes(ymin=avg_reflect-sd_reflect, ymax=avg_reflect+sd_reflect, fill=Treatment), alpha=0.25) +
  facet_grid(Site ~ Block) + 
  scale_color_manual(values=c("CT" = "forestgreen", "CT1"="darkolivegreen2", "CT2"="darkolivegreen3",
                              "N" = "dodgerblue", "NO3" = "skyblue", "NH4" = "deepskyblue",
                              "P" = "red2",
                              "NP" = pur_pal[5],
                              "F0.5" = pur_pal[1],
                              "F1" = pur_pal[2],
                              "F2" = pur_pal[3],
                              "F5" = pur_pal[4],
                              "F10" = pur_pal[5])) + 
  scale_fill_manual(values=c("CT" = "forestgreen", "CT1"="darkolivegreen2", "CT2"="darkolivegreen3",
                              "N" = "dodgerblue", "NO3" = "skyblue", "NH4" = "deepskyblue",
                              "P" = "red2",
                              "NP" = pur_pal[5],
                              "F0.5" = pur_pal[1],
                              "F1" = pur_pal[2],
                              "F2" = pur_pal[3],
                              "F5" = pur_pal[4],
                              "F10" = pur_pal[5]))

```

## Plot Spectra: Site vs. Date
Average plot averages by block. NOTE: Ask Laura what the correct error propogation is here.

```{r plot_spectra_dates, echo=F}
# PLOT SELECTION 
dates <- lubridate::ymd("2018-06-22", "2018-06-25")
sites <- c("HST", "MAT", "LMAT",  "MNAT", "NANT", "WSG", "DHT", "SHB")
blocks <- c("B1", "B2", "B3", "B4")
trtmts <- c("N", "NP", CT, NP_gradient) 
measures <- c("1", "2", "3", "4", "5")

# Data Comparison Format
df_dates <- df_tidy %>% 
  filter(Site %in% sites) %>% 
  filter(Block %in% blocks) %>% 
  filter(Treatment %in% trtmts) %>% 
  filter(Date %in% dates) %>% 
  group_by(Site, Block, Treatment, Date, Wavelength) %>% # average measurements by plot
  summarize(
    avg_reflect = mean(Reflectance),
    max_ref = max(Reflectance),
    min_ref = min(Reflectance),
    sd_reflect = sd(Reflectance)
    )  %>% 
  group_by(Site, Treatment, Date, Wavelength) %>% # average plots by block
  summarize(
    block_avg_reflect = mean(avg_reflect),
    max_ref = max(avg_reflect),
    min_ref = min(avg_reflect),
    sd_reflect = sd(avg_reflect)
    ) 

ggplot(data = df_dates, mapping = aes(x = Wavelength, y = block_avg_reflect)) +
  geom_line(aes(color=Treatment)) + 
  geom_ribbon(aes(ymin=block_avg_reflect-sd_reflect, ymax=block_avg_reflect+sd_reflect, fill=Treatment), alpha=0.25) +
  facet_grid(Site ~ Date) + 
  scale_color_manual(values=c("CT" = "forestgreen", "CT1"="darkolivegreen2", "CT2"="darkolivegreen3",
                              "N" = "dodgerblue", "NO3" = "skyblue", "NH4" = "deepskyblue",
                              "P" = "red2",
                              "NP" = pur_pal[5],
                              "F0.5" = pur_pal[1],
                              "F1" = pur_pal[2],
                              "F2" = pur_pal[3],
                              "F5" = pur_pal[4],
                              "F10" = pur_pal[5])) + 
  scale_fill_manual(values=c("CT" = "forestgreen", "CT1"="darkolivegreen2", "CT2"="darkolivegreen3",
                              "N" = "dodgerblue", "NO3" = "skyblue", "NH4" = "deepskyblue",
                              "P" = "red2",
                              "NP" = pur_pal[5],
                              "F0.5" = pur_pal[1],
                              "F1" = pur_pal[2],
                              "F2" = pur_pal[3],
                              "F5" = pur_pal[4],
                              "F10" = pur_pal[5]))

```

# Calculate Vegetation Indices

Currently, this only works for NDVI, EVI, and EVI2 as I haven't worked out spectral interpolation yet and the other indices need reflectance at a specific value (not a range). 

## Plot NDVI: Site vs. Block
```{r ndvi, echo=F}

# SELECTION
sites <-c("MAT", "DHT", "WSG", "LMAT")
blocks <- c("B1", "B2", "B3", "B4")
trtmts <- c(CT,"NP", "F10") 

ndvi_types <- df_tidy %>% 
  filter(Site %in% sites) %>% 
  filter(Block %in% blocks) %>% 
  filter(Treatment %in% trtmts) %>% 
  calculate_index(indices = "NDVI") # function in "unispec_functions.R"


ndvi_plot <- ndvi_types %>% 
  group_by(Site, Block, Treatment, Measurement, Date) %>% 
  summarise(
    avg_ndvi = mean(NDVI),
    sd_ndvi = sd(NDVI)
  )

ggplot(data = ndvi_plot, mapping = aes(x = Date, y = avg_ndvi, color = Treatment)) +
  geom_point() +
  geom_line() + 
  geom_boxplot() +
  #geom_errorbar(aes(ymin = avg_ndvi-sd_ndvi, ymax= avg_ndvi + sd_ndvi), width=2) + 
  facet_grid( Site ~ Block) +  
  scale_color_manual(values=c("CT" = "forestgreen", "CT1"="darkolivegreen2", "CT2"="darkolivegreen3",
                              "N" = "dodgerblue", "NO3" = "skyblue", "NH4" = "deepskyblue",
                              "P" = "red2",
                              "NP" = pur_pal[5],
                              "F0.5" = pur_pal[1],
                              "F1" = pur_pal[2],
                              "F2" = pur_pal[3],
                              "F5" = pur_pal[4],
                              "F10" = pur_pal[5])) 
```

## Save Vegetation Index Data
Append data to yearly r dataframe or .csv file. Write code to read in saved data and remove duplicate rows. >> ASK JIM: I'm not sure what the best data organization system is yet. 


